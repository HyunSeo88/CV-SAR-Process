#!/usr/bin/env python3
# patch_extractor_gpu_enhanced.py - GPU ê°€ì† ë° ì¬ì‹œë„ ë¡œì§ í¬í•¨
import os
import sys
import traceback
import time
import gc
import numpy as np
import torch
import concurrent.futures
from threading import Lock
from esa_snappy import ProductIO, GPF, HashMap
import logging
from typing import Dict, List, Optional, Tuple, Any
import weakref
import psutil

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('patch_extraction_gpu_enhanced.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# GPU ê°€ì† ì˜µì…˜
try:
    import cupy as cp
    HAS_CUPY = True
    logger.info("CuPy ì‚¬ìš© ê°€ëŠ¥ - GPU FFT ê°€ì† í™œì„±í™”")
except ImportError:
    HAS_CUPY = False
    cp = None
    logger.info("CuPy ì—†ìŒ - CPU FFT ì‚¬ìš©")



# CV-SAR SR ìƒì‚° ìµœì í™” ì„¤ì •
PATCH_W, PATCH_H = 256, 512
STRIDE_X, STRIDE_Y = 256, 512
MAX_FILES = None  # âœ… ì „ì²´ íŒŒì¼ ì²˜ë¦¬ë¡œ ìˆ˜ì •
ENABLE_SUBAPERTURE = True
SUBAPERTURE_VIEWS = 5
ENABLE_DUAL_POL = True
LAZY_SUBAPERTURE = True
MAX_RETRIES = 3  # âœ… ì‹¤íŒ¨ íŒ¨ì¹˜ ì¬ì‹œë„ íšŸìˆ˜
USE_GPU_FFT = HAS_CUPY and torch.cuda.is_available()  # âœ… GPU FFT ì‚¬ìš© ì—¬ë¶€

# í’ˆì§ˆ ê²€ì¦ ì„ê³„ê°’
MIN_CROSS_POL_COHERENCE = 0.95
MIN_ENERGY_RATIO = 0.95
MIN_PHASE_VARIANCE = 1e-6

# ê²½ë¡œ ì„¤ì •
IN_DIR = r'D:\Sentinel-1\data\processed_1'
OUT_DIR = r'D:\Sentinel-1\data\processed_2_gpu_enhanced'
os.makedirs(OUT_DIR, exist_ok=True)

# ì „ì—­ ë©”ëª¨ë¦¬ ê´€ë¦¬
_memory_lock = Lock()
_active_products = weakref.WeakSet()

class GPUAccelerator:
    """GPU ê°€ì† í—¬í¼ í´ë˜ìŠ¤"""
    
    @staticmethod
    def to_gpu(array: np.ndarray):
        """NumPy ë°°ì—´ì„ GPUë¡œ ì „ì†¡"""
        if USE_GPU_FFT and HAS_CUPY:
            return cp.asarray(array)
        elif torch.cuda.is_available():
            return torch.from_numpy(array).cuda()
        return array
    
    @staticmethod
    def to_cpu(array):
        """GPU ë°°ì—´ì„ CPUë¡œ ì „ì†¡"""
        if hasattr(array, 'get'):  # CuPy array
            return array.get()
        elif hasattr(array, 'cpu'):  # PyTorch tensor
            return array.cpu().numpy()
        return array
    
    @staticmethod
    def fft2_gpu(array: np.ndarray):
        """GPU ê°€ì† 2D FFT"""
        if USE_GPU_FFT and HAS_CUPY:
            gpu_array = cp.asarray(array)
            fft_result = cp.fft.fft2(gpu_array)
            return fft_result
        elif torch.cuda.is_available():
            gpu_tensor = torch.from_numpy(array).cuda()
            fft_result = torch.fft.fft2(gpu_tensor)
            return fft_result
        return np.fft.fft2(array)
    
    @staticmethod
    def ifft2_gpu(array):
        """GPU ê°€ì† 2D IFFT"""
        if USE_GPU_FFT and HAS_CUPY:
            if not isinstance(array, cp.ndarray):
                array = cp.asarray(array)
            ifft_result = cp.fft.ifft2(array)
            return ifft_result
        elif torch.cuda.is_available():
            if not isinstance(array, torch.Tensor):
                array = torch.from_numpy(array).cuda()
            ifft_result = torch.fft.ifft2(array)
            return ifft_result
        return np.fft.ifft2(array)

def enhanced_subaperture_decomposition_gpu(complex_data: np.ndarray, num_views: int = 5) -> Tuple[Optional[np.ndarray], Dict[str, float]]:
    """
    GPU ê°€ì† Subaperture ë¶„í•´
    """
    try:
        h, w = complex_data.shape
        logger.debug(f"GPU Subaperture ë¶„í•´: {h}x{w}, {num_views}ê°œ ì‹œê°")
        
        # ì ì‘ì  ë¶„í•´ ê³„íš
        aspect_ratio = h / w
        if aspect_ratio > 1.5:
            azimuth_views = max(3, int(num_views * 0.6))
            range_views = num_views - azimuth_views
        else:
            range_views = max(3, int(num_views * 0.6))
            azimuth_views = num_views - range_views
        
        # âœ… GPU ê°€ì† FFT
        start_fft = time.time()
        fft_data = GPUAccelerator.fft2_gpu(complex_data)
        fft_time = time.time() - start_fft
        logger.debug(f"{'GPU' if USE_GPU_FFT else 'CPU'} FFT ì‹œê°„: {fft_time:.3f}ì´ˆ")
        
        subapertures = []
        
        # ë°©ìœ„ê° ë°©í–¥ ë¶„í•´
        azimuth_step = h // azimuth_views
        for i in range(azimuth_views):
            start_h = i * azimuth_step
            end_h = min((i + 1) * azimuth_step, h)
            
            window_length = end_h - start_h
            if window_length > 0:
                # Hamming window (GPUì—ì„œ ê³„ì‚°)
                if USE_GPU_FFT and HAS_CUPY:
                    window = cp.hamming(window_length)[:, cp.newaxis]
                    sub_fft = cp.zeros_like(fft_data)
                else:
                    window = np.hamming(window_length)[:, np.newaxis]
                    sub_fft = np.zeros_like(GPUAccelerator.to_cpu(fft_data))
                
                if USE_GPU_FFT:
                    sub_fft[start_h:end_h, :] = fft_data[start_h:end_h, :] * window
                    subaperture = GPUAccelerator.ifft2_gpu(sub_fft)
                    subaperture_cpu = GPUAccelerator.to_cpu(subaperture).astype(np.complex64)
                else:
                    fft_cpu = GPUAccelerator.to_cpu(fft_data)
                    sub_fft[start_h:end_h, :] = fft_cpu[start_h:end_h, :] * window
                    subaperture_cpu = np.fft.ifft2(sub_fft).astype(np.complex64)
                
                subapertures.append(subaperture_cpu)
        
        # ê±°ë¦¬ ë°©í–¥ ë¶„í•´
        range_step = w // range_views
        for i in range(range_views):
            start_w = i * range_step
            end_w = min((i + 1) * range_step, w)
            
            window_length = end_w - start_w
            if window_length > 0:
                if USE_GPU_FFT and HAS_CUPY:
                    window = cp.hamming(window_length)[cp.newaxis, :]
                    sub_fft = cp.zeros_like(fft_data)
                else:
                    window = np.hamming(window_length)[np.newaxis, :]
                    sub_fft = np.zeros_like(GPUAccelerator.to_cpu(fft_data))
                
                if USE_GPU_FFT:
                    sub_fft[:, start_w:end_w] = fft_data[:, start_w:end_w] * window
                    subaperture = GPUAccelerator.ifft2_gpu(sub_fft)
                    subaperture_cpu = GPUAccelerator.to_cpu(subaperture).astype(np.complex64)
                else:
                    fft_cpu = GPUAccelerator.to_cpu(fft_data)
                    sub_fft[:, start_w:end_w] = fft_cpu[:, start_w:end_w] * window
                    subaperture_cpu = np.fft.ifft2(sub_fft).astype(np.complex64)
                
                subapertures.append(subaperture_cpu)
        
        if not subapertures:
            return None, {}
        
        result = np.stack(subapertures, axis=0)
        
        # ì •í™•ë„ ê²€ì¦
        from workflows.patch_extractor_production_final import validate_subaperture_accuracy
        is_valid, metrics = validate_subaperture_accuracy(complex_data, result)
        
        total_time = time.time() - start_fft
        metrics['fft_time'] = float(fft_time)
        metrics['total_time'] = float(total_time)
        metrics['gpu_used'] = USE_GPU_FFT
        
        logger.debug(f"Subaperture ê²€ì¦: {metrics}")
        
        if not is_valid:
            logger.warning(f"Subaperture í’ˆì§ˆ ë¯¸ë‹¬: energy_ratio={metrics.get('energy_ratio', 0):.3f}")
            return None, metrics
        
        return result, metrics
        
    except Exception as e:
        logger.warning(f"GPU Subaperture ë¶„í•´ ì‹¤íŒ¨: {str(e)}")
        return None, {}

def process_single_patch_with_retry(args, max_retries: int = 3) -> Tuple[bool, Dict]:
    """
    âœ… ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ë‹¨ì¼ íŒ¨ì¹˜ ì²˜ë¦¬
    """
    retry_count = 0
    last_error = None
    
    while retry_count < max_retries:
        try:
            # ê¸°ì¡´ process_single_patch ë¡œì§ import
            from workflows.patch_extractor_production_final import (
                extract_dual_pol_complex_patch,
                calculate_enhanced_coherence_features,
                save_enhanced_patch_data,
                LazySubaperture
            )
            
            subset, complex_pairs, x, y, out_path_base = args
            
            # 1. Dual-pol ë³µì†Œìˆ˜ ì¶”ì¶œ
            complex_data_dict, extract_time, extract_msg = extract_dual_pol_complex_patch(
                subset, complex_pairs, x, y
            )
            if complex_data_dict is None:
                raise Exception(f"ë³µì†Œìˆ˜ ì¶”ì¶œ ì‹¤íŒ¨: {extract_msg}")
            
            # 2. Enhanced coherence íŠ¹ì§• ê³„ì‚°
            coherence_start = time.time()
            features, quality_metrics = calculate_enhanced_coherence_features(complex_data_dict)
            if features is None:
                logger.warning(f"Patch ({x}, {y}) í’ˆì§ˆ ë¯¸ë‹¬: {quality_metrics}")
                if retry_count < max_retries - 1:
                    logger.info(f"ì¬ì‹œë„ {retry_count + 1}/{max_retries}...")
                    retry_count += 1
                    time.sleep(0.5)  # ì§§ì€ ëŒ€ê¸°
                    continue
                else:
                    return False, {
                        'error': f'í’ˆì§ˆ ë¯¸ë‹¬ (ì¬ì‹œë„ {max_retries}íšŒ ì‹¤íŒ¨): {quality_metrics}',
                        'position': (x, y),
                        'quality_metrics': quality_metrics
                    }
            
            # 3. GPU ê°€ì† Subaperture ë¶„í•´
            lazy_subaperture = None
            if ENABLE_SUBAPERTURE and complex_data_dict:
                first_pol_data = next(iter(complex_data_dict.values()))
                
                # GPU ê°€ì† ë²„ì „ ì‚¬ìš©
                class LazySubapertureGPU(LazySubaperture):
                    def compute(self):
                        if not self._is_computed:
                            logger.debug("GPU LazySubaperture ê³„ì‚° ì‹¤í–‰")
                            self._computed, self._metrics = enhanced_subaperture_decomposition_gpu(
                                self.complex_data, self.num_views
                            )
                            self._is_computed = True
                        return self._computed, self._metrics
                
                lazy_subaperture = LazySubapertureGPU(first_pol_data, SUBAPERTURE_VIEWS)
            
            coherence_time = time.time() - coherence_start
            
            # 4. ë°ì´í„° íŒ¨í‚¤ì§•
            patch_data = {
                'complex_data': complex_data_dict,
                'features': features,
                'quality_metrics': quality_metrics,
                'subapertures': lazy_subaperture
            }
            
            # 5. ì €ì¥
            save_success, save_time, save_msg, save_metrics = save_enhanced_patch_data(
                patch_data, out_path_base, x, y
            )
            
            if not save_success:
                raise Exception(f"ì €ì¥ ì‹¤íŒ¨: {save_msg}")
            
            # ì„±ê³µ
            all_metrics = {}
            all_metrics.update(quality_metrics)
            all_metrics.update(save_metrics)
            
            result = {
                'position': (x, y),
                'extract_time': extract_time,
                'coherence_time': coherence_time,
                'save_time': save_time,
                'total_time': extract_time + coherence_time + save_time,
                'polarizations': list(complex_data_dict.keys()),
                'save_msg': save_msg,
                'quality_metrics': all_metrics,
                'retry_count': retry_count,
                'gpu_used': USE_GPU_FFT
            }
            
            return True, result
            
        except Exception as e:
            last_error = str(e)
            retry_count += 1
            if retry_count < max_retries:
                logger.warning(f"íŒ¨ì¹˜ ({x}, {y}) ì²˜ë¦¬ ì‹¤íŒ¨ (ì¬ì‹œë„ {retry_count}/{max_retries}): {last_error}")
                time.sleep(1.0 * retry_count)  # ì ì§„ì  ëŒ€ê¸°
            else:
                logger.error(f"íŒ¨ì¹˜ ({x}, {y}) ìµœì¢… ì‹¤íŒ¨: {last_error}")
                return False, {
                    'error': f'ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼: {last_error}',
                    'position': (x, y),
                    'retry_count': retry_count
                }
    
    return False, {'error': 'ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜', 'position': args[2:4]}

def extract_gpu_enhanced_patches(dim_path: str) -> int:
    """
    GPU ê°€ì† ë° ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ íŒ¨ì¹˜ ì¶”ì¶œ
    """
    logger.info(f"GPU Enhanced íŒ¨ì¹˜ ì¶”ì¶œ: {os.path.basename(dim_path)}")
    logger.info(f"GPU FFT ì‚¬ìš©: {'âœ… í™œì„±í™”' if USE_GPU_FFT else 'âŒ CPU ëª¨ë“œ'}")
    
    # ë‚˜ë¨¸ì§€ ë¡œì§ì€ production_finalê³¼ ë™ì¼í•˜ì§€ë§Œ process_single_patch_with_retry ì‚¬ìš©
    from workflows.patch_extractor_production_final import (
        MemoryMonitor, MemoryManager, get_all_complex_band_pairs,
        get_optimal_workers
    )
    
    MemoryMonitor.log_memory_usage("ì‹œì‘")
    
    prod = None
    patch_count = 0
    start_time = time.time()
    
    try:
        # ì œí’ˆ ë¡œë“œ
        prod = ProductIO.readProduct(dim_path)
        if prod is None:
            logger.error("ì œí’ˆ ë¡œë“œ ì‹¤íŒ¨")
            return 0
        
        MemoryManager.register_product(prod)
        
        width = prod.getSceneRasterWidth()
        height = prod.getSceneRasterHeight()
        logger.info(f"ì´ë¯¸ì§€ í¬ê¸°: {width} x {height}")
        
        # ë³µì†Œìˆ˜ ë°´ë“œ ìŒ ì°¾ê¸°
        complex_pairs = get_all_complex_band_pairs(prod)
        if complex_pairs is None:
            return 0
        
        base = os.path.basename(dim_path).replace('.dim', '')
        
        # ì˜ˆìƒ íŒ¨ì¹˜ ìˆ˜ ê³„ì‚°
        expected_patches_x = (width - PATCH_W) // STRIDE_X + 1
        expected_patches_y = (height - PATCH_H) // STRIDE_Y + 1
        total_expected = expected_patches_x * expected_patches_y
        logger.info(f"ì˜ˆìƒ íŒ¨ì¹˜ ìˆ˜: {total_expected}")
        
        # GPU ë©”ëª¨ë¦¬ í™•ì¸
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            logger.info(f"GPU ë©”ëª¨ë¦¬: {gpu_memory:.2f} GB")
        
        # ë™ì  ì›Œì»¤ ìˆ˜
        optimal_workers = get_optimal_workers(total_expected)
        logger.info(f"ìµœì í™”ëœ ì›Œì»¤ ìˆ˜: {optimal_workers}")
        
        # ì„œë¸Œì…‹ íŒŒë¼ë¯¸í„°
        subset_params_base = HashMap()
        subset_params_base.put('copyMetadata', 'false')
        
        # í†µê³„ ë³€ìˆ˜
        successful_patches = 0
        failed_patches = 0
        retried_patches = 0
        gpu_speedup_total = 0
        
        # ë°°ì¹˜ ì²˜ë¦¬
        batch_size = min(100, total_expected)
        
        for batch_start in range(0, total_expected, batch_size):
            batch_end = min(batch_start + batch_size, total_expected)
            batch_args = []
            
            # ë°°ì¹˜ ì¤€ë¹„
            for patch_idx in range(batch_start, batch_end):
                y_idx = patch_idx // expected_patches_x
                x_idx = patch_idx % expected_patches_x
                
                x = x_idx * STRIDE_X
                y = y_idx * STRIDE_Y
                
                if x + PATCH_W > width or y + PATCH_H > height:
                    continue
                
                # ì¶œë ¥ ê²½ë¡œ
                out_path_base = os.path.join(OUT_DIR, f'{base}_{complex_pairs["subswath"]}')
                complex_path = f"{out_path_base}_dual_pol_complex_{x}_{y}.npy"
                
                # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” íŒŒì¼ ê±´ë„ˆë›°ê¸°
                if os.path.exists(complex_path):
                    patch_count += 1
                    continue
                
                # ì„œë¸Œì…‹ ìƒì„±
                subset_params = HashMap(subset_params_base)
                subset_params.put('pixelRegion', f'{x},{y},{PATCH_W},{PATCH_H}')
                
                subset = GPF.createProduct('Subset', subset_params, prod)
                if subset is None:
                    logger.warning(f"ì„œë¸Œì…‹ ìƒì„± ì‹¤íŒ¨: ({x}, {y})")
                    continue
                
                MemoryManager.register_product(subset)
                batch_args.append((subset, complex_pairs, x, y, out_path_base))
            
            # ë³‘ë ¬ ì²˜ë¦¬ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
            if batch_args:
                current_workers = get_optimal_workers(len(batch_args), optimal_workers)
                logger.info(f"ë°°ì¹˜ ì²˜ë¦¬: {len(batch_args)}ê°œ íŒ¨ì¹˜, {current_workers}ê°œ ì›Œì»¤")
                
                with concurrent.futures.ThreadPoolExecutor(max_workers=current_workers) as executor:
                    batch_results = list(executor.map(
                        lambda args: process_single_patch_with_retry(args, MAX_RETRIES),
                        batch_args
                    ))
                
                # ê²°ê³¼ ì²˜ë¦¬
                for success, result in batch_results:
                    if success:
                        successful_patches += 1
                        if result.get('retry_count', 0) > 0:
                            retried_patches += 1
                        if result.get('gpu_used', False):
                            gpu_speedup_total += 1
                    else:
                        failed_patches += 1
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                for subset, _, _, _, _ in batch_args:
                    MemoryManager.safe_dispose(subset)
                
                MemoryManager.cleanup_products()
            
            patch_count = successful_patches
        
        # ìµœì¢… í†µê³„
        elapsed = time.time() - start_time
        rate = successful_patches / elapsed if elapsed > 0 else 0
        
        logger.info(f"íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: {os.path.basename(dim_path)}")
        logger.info(f"ì„±ê³µ: {successful_patches}ê°œ, ì‹¤íŒ¨: {failed_patches}ê°œ, ì¬ì‹œë„: {retried_patches}ê°œ")
        logger.info(f"GPU ê°€ì† ì‚¬ìš©: {gpu_speedup_total}ê°œ íŒ¨ì¹˜")
        logger.info(f"ì†Œìš”ì‹œê°„: {elapsed/60:.1f}ë¶„, ì†ë„: {rate:.2f}íŒ¨ì¹˜/ì´ˆ")
        
        MemoryMonitor.log_memory_usage("ì™„ë£Œ")
        
        return successful_patches
        
    except Exception as e:
        logger.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return 0
        
    finally:
        if prod is not None:
            MemoryManager.safe_dispose(prod)
        MemoryManager.cleanup_products()

def main():
    """GPU Enhanced ë©”ì¸"""
    logger.info("=" * 90)
    logger.info("ğŸš€ CV-SAR SR GPU Enhanced Pipeline")
    logger.info("ê°œì„ ì‚¬í•­:")
    logger.info(f"  âœ… GPU FFT ê°€ì†: {'í™œì„±í™”' if USE_GPU_FFT else 'ë¹„í™œì„±í™”'}")
    logger.info(f"  âœ… ì‹¤íŒ¨ íŒ¨ì¹˜ ì¬ì‹œë„: ìµœëŒ€ {MAX_RETRIES}íšŒ")
    logger.info(f"  âœ… ì „ì²´ íŒŒì¼ ì²˜ë¦¬: MAX_FILES={MAX_FILES}")
    logger.info("=" * 90)
    
    # GPU ì •ë³´
    if torch.cuda.is_available():
        logger.info(f"GPU ì¥ì¹˜: {torch.cuda.get_device_name(0)}")
        logger.info(f"GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
    else:
        logger.info("GPU ì‚¬ìš© ë¶ˆê°€ - CPU ëª¨ë“œ")
    
    # ì…ë ¥ í™•ì¸
    if not os.path.exists(IN_DIR):
        logger.error(f"ì…ë ¥ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {IN_DIR}")
        return
    
    # .dim íŒŒì¼ ì°¾ê¸°
    dim_files = [f for f in sorted(os.listdir(IN_DIR)) if f.endswith('.dim')]
    if MAX_FILES is not None:
        dim_files = dim_files[:MAX_FILES]
    
    logger.info(f"ì²˜ë¦¬í•  .dim íŒŒì¼ ìˆ˜: {len(dim_files)}")
    
    if not dim_files:
        logger.warning("ì²˜ë¦¬í•  .dim íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    total_patches = 0
    total_start_time = time.time()
    
    # íŒŒì¼ ì²˜ë¦¬
    for file_idx, file in enumerate(dim_files, 1):
        logger.info(f"\n[{file_idx}/{len(dim_files)}] GPU Enhanced ì²˜ë¦¬: {file}")
        
        try:
            dim_path = os.path.join(IN_DIR, file)
            patches_created = extract_gpu_enhanced_patches(dim_path)
            total_patches += patches_created
            
        except Exception as e:
            logger.error(f"íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨ {file}: {str(e)}")
            continue
    
    # ìµœì¢… ê²°ê³¼
    total_elapsed = time.time() - total_start_time
    avg_rate = total_patches / total_elapsed if total_elapsed > 0 else 0
    
    logger.info("\n" + "=" * 90)
    logger.info("ğŸ‰ GPU Enhanced ì²˜ë¦¬ ì™„ë£Œ!")
    logger.info(f"ì´ íŒ¨ì¹˜: {total_patches}ê°œ")
    logger.info(f"ì´ ì‹œê°„: {total_elapsed/60:.1f}ë¶„")
    logger.info(f"í‰ê·  ì†ë„: {avg_rate:.2f}íŒ¨ì¹˜/ì´ˆ")
    
    # GPU ê°€ì† íš¨ê³¼
    if USE_GPU_FFT:
        logger.info("âœ… GPU FFT ê°€ì†ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ")
    
    logger.info("=" * 90)

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        logger.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        logger.error(f"í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        logger.debug(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}") 